{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNd8TtF+pImqieCpuPZGG7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phenixua/HW_10/blob/main/HW_10_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkpnIjEQagjD",
        "outputId": "d2f37268-1a9d-4933-e840-0d25895971de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/100\n",
            "422/422 [==============================] - 54s 116ms/step - loss: 0.6896 - accuracy: 0.7495 - val_loss: 0.4193 - val_accuracy: 0.8465\n",
            "Epoch 2/100\n",
            "422/422 [==============================] - 44s 105ms/step - loss: 0.4412 - accuracy: 0.8413 - val_loss: 0.3570 - val_accuracy: 0.8660\n",
            "Epoch 3/100\n",
            "422/422 [==============================] - 47s 110ms/step - loss: 0.3843 - accuracy: 0.8627 - val_loss: 0.3216 - val_accuracy: 0.8797\n",
            "Epoch 4/100\n",
            "422/422 [==============================] - 46s 109ms/step - loss: 0.3497 - accuracy: 0.8740 - val_loss: 0.3093 - val_accuracy: 0.8833\n",
            "Epoch 5/100\n",
            "422/422 [==============================] - 46s 108ms/step - loss: 0.3249 - accuracy: 0.8824 - val_loss: 0.2937 - val_accuracy: 0.8893\n",
            "Epoch 6/100\n",
            "422/422 [==============================] - 44s 105ms/step - loss: 0.3034 - accuracy: 0.8920 - val_loss: 0.2771 - val_accuracy: 0.8988\n",
            "Epoch 7/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 0.2886 - accuracy: 0.8950 - val_loss: 0.2697 - val_accuracy: 0.8988\n",
            "Epoch 8/100\n",
            "422/422 [==============================] - 42s 101ms/step - loss: 0.2718 - accuracy: 0.9007 - val_loss: 0.2685 - val_accuracy: 0.9002\n",
            "Epoch 9/100\n",
            "422/422 [==============================] - 44s 103ms/step - loss: 0.2618 - accuracy: 0.9057 - val_loss: 0.2622 - val_accuracy: 0.8980\n",
            "Epoch 10/100\n",
            "422/422 [==============================] - 42s 100ms/step - loss: 0.2488 - accuracy: 0.9089 - val_loss: 0.2437 - val_accuracy: 0.9117\n",
            "Epoch 11/100\n",
            "422/422 [==============================] - 44s 104ms/step - loss: 0.2381 - accuracy: 0.9137 - val_loss: 0.2412 - val_accuracy: 0.9110\n",
            "Epoch 12/100\n",
            "422/422 [==============================] - 42s 100ms/step - loss: 0.2271 - accuracy: 0.9172 - val_loss: 0.2359 - val_accuracy: 0.9115\n",
            "Epoch 13/100\n",
            "422/422 [==============================] - 43s 102ms/step - loss: 0.2204 - accuracy: 0.9192 - val_loss: 0.2360 - val_accuracy: 0.9140\n",
            "Epoch 14/100\n",
            "422/422 [==============================] - 43s 103ms/step - loss: 0.2113 - accuracy: 0.9228 - val_loss: 0.2384 - val_accuracy: 0.9123\n",
            "Epoch 15/100\n",
            "422/422 [==============================] - 42s 100ms/step - loss: 0.2008 - accuracy: 0.9261 - val_loss: 0.2315 - val_accuracy: 0.9152\n",
            "Epoch 16/100\n",
            "422/422 [==============================] - 43s 103ms/step - loss: 0.1953 - accuracy: 0.9275 - val_loss: 0.2303 - val_accuracy: 0.9183\n",
            "Epoch 17/100\n",
            "422/422 [==============================] - 42s 100ms/step - loss: 0.1875 - accuracy: 0.9298 - val_loss: 0.2374 - val_accuracy: 0.9170\n",
            "Epoch 18/100\n",
            "422/422 [==============================] - 43s 103ms/step - loss: 0.1822 - accuracy: 0.9325 - val_loss: 0.2331 - val_accuracy: 0.9170\n",
            "Epoch 19/100\n",
            "422/422 [==============================] - 43s 102ms/step - loss: 0.1751 - accuracy: 0.9344 - val_loss: 0.2361 - val_accuracy: 0.9165\n",
            "Epoch 20/100\n",
            "422/422 [==============================] - 42s 99ms/step - loss: 0.1673 - accuracy: 0.9372 - val_loss: 0.2290 - val_accuracy: 0.9195\n",
            "Epoch 21/100\n",
            "422/422 [==============================] - 42s 100ms/step - loss: 0.1630 - accuracy: 0.9392 - val_loss: 0.2327 - val_accuracy: 0.9235\n",
            "Epoch 22/100\n",
            "422/422 [==============================] - 45s 106ms/step - loss: 0.1581 - accuracy: 0.9411 - val_loss: 0.2252 - val_accuracy: 0.9217\n",
            "Epoch 23/100\n",
            "422/422 [==============================] - 42s 99ms/step - loss: 0.1481 - accuracy: 0.9434 - val_loss: 0.2359 - val_accuracy: 0.9207\n",
            "Epoch 24/100\n",
            "422/422 [==============================] - 42s 99ms/step - loss: 0.1440 - accuracy: 0.9462 - val_loss: 0.2332 - val_accuracy: 0.9228\n",
            "Epoch 25/100\n",
            "422/422 [==============================] - 44s 103ms/step - loss: 0.1398 - accuracy: 0.9473 - val_loss: 0.2330 - val_accuracy: 0.9243\n",
            "Epoch 26/100\n",
            "422/422 [==============================] - 42s 99ms/step - loss: 0.1382 - accuracy: 0.9473 - val_loss: 0.2416 - val_accuracy: 0.9233\n",
            "Epoch 27/100\n",
            "422/422 [==============================] - 41s 98ms/step - loss: 0.1313 - accuracy: 0.9493 - val_loss: 0.2610 - val_accuracy: 0.9233\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2877 - accuracy: 0.9172\n",
            "Test Loss: 0.28766798973083496\n",
            "Test Accuracy: 0.9172000288963318\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Завантаження та підготовка даних\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# Кодування міток класів у формат one-hot\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Побудова моделі згорткової нейронної мережі\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компіляція моделі\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Додавання ранньої зупинки\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# Навчання моделі з ранньою зупинкою та використанням валідаційного розбиття\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Оцінка моделі на тестових даних\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точність для згорткової нейронної мережі на даних Fashion MNIST (91.72%), якщо її порівняти з точністю, що була отримана для багатошарової нейронної мережі в попередньому завданні (близько 91.21%), то за цими результатами можна зробити висновок, що згорткова нейронна мережа показує схожу або трохи кращу точність порівняно з багатошаровою мережею для задачі класифікації зображень з датасету Fashion MNIST."
      ],
      "metadata": {
        "id": "URt24N-gijeh"
      }
    }
  ]
}